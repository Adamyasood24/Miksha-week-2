{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "d8vWVUMDYAi3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load NLTK\n",
        "import nltk\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.corpus import subjectivity\n",
        "from nltk.sentiment import SentimentAnalyzer\n",
        "from nltk.sentiment.util import *\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.classify import SklearnClassifier\n",
        "\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "from subprocess import check_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nltk.download('subjectivity')\n",
        "n_instances = 100\n",
        "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')[:n_instances]]\n",
        "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')[:n_instances]]\n",
        "len(subj_docs), len(obj_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3_-fBtkY9rn",
        "outputId": "6e8c1b80-e591-4487-e48d-414e436e095c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package subjectivity to /root/nltk_data...\n",
            "[nltk_data]   Package subjectivity is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subj_docs[0]\n",
        "train_subj_docs = subj_docs[:80]\n",
        "test_subj_docs = subj_docs[80:100]\n",
        "train_obj_docs = obj_docs[:80]\n",
        "test_obj_docs = obj_docs[80:100]\n",
        "training_docs = train_subj_docs+train_obj_docs\n",
        "testing_docs = test_subj_docs+test_obj_docs\n",
        "\n",
        "sentim_analyzer = SentimentAnalyzer()\n",
        "all_words_neg = sentim_analyzer.all_words([mark_negation(doc) for doc in training_docs])"
      ],
      "metadata": {
        "id": "oLsrNsSJY-wv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq=4)\n",
        "len(unigram_feats)\n",
        "# output: 83\n",
        "sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)"
      ],
      "metadata": {
        "id": "MupOpdKFZDqt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = sentim_analyzer.apply_features(training_docs)\n",
        "test_set = sentim_analyzer.apply_features(testing_docs)"
      ],
      "metadata": {
        "id": "N70YZZ2AZPzy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = NaiveBayesClassifier.train\n",
        "classifier = sentim_analyzer.train(trainer, training_set)\n",
        "# output: Training classifier\n",
        "for key,value in sorted(sentim_analyzer.evaluate(test_set).items()):\n",
        "    print('{0}: {1}'.format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNHFy5NeZU7n",
        "outputId": "e7a3e3c6-1bcd-4216-afe0-920ae2f9c43f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training classifier\n",
            "Evaluating NaiveBayesClassifier results...\n",
            "Accuracy: 0.8\n",
            "F-measure [obj]: 0.8\n",
            "F-measure [subj]: 0.8\n",
            "Precision [obj]: 0.8\n",
            "Precision [subj]: 0.8\n",
            "Recall [obj]: 0.8\n",
            "Recall [subj]: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "irMSz-EpZxJ5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\"Adamya is smart, handsome, and funny.\", #\n",
        "   \"Adamya is smart, handsome, and funny!\",\n",
        "   \"Adamya is very smart, handsome, and funny.\",\n",
        "   \"Sood is VERY SMART, handsome, and FUNNY.\",\n",
        "   \"sood is VERY SMART, handsome, and FUNNY!!!\",\n",
        "   \"sood is VERY SMART, really handsome, and INCREDIBLY FUNNY!!!\",\n",
        "   \"The book was good.\",\n",
        "   \"The book was kind of good.\",\n",
        "   \"The plot was good, but the characters are uncompelling and the dialog is not great.\",\n",
        "   \"A really bad, horrible book.\",\n",
        "   \"At least it isn't a horrible book.\",\n",
        "   \":) and :D\",\n",
        "   \"\",\n",
        "   \"Today sucks!\",\n",
        "   \"Today sucks!\",\n",
        "   \"Today SUcks!\",\n",
        "   \"Today kinda sucks! But I'll  make it , lol\"\n",
        "]\n",
        "tricky_sentences = [\n",
        "    \"Most automated sentiment analysis tools are shit.\",\n",
        "    \"VADER sentiment analysis is the shit.\",\n",
        "    \"Sentiment analysis has never been good.\",\n",
        "    \"Sentiment analysis with Adam has never been this good.\",\n",
        "    \"Adam has never been so entertaining.\",\n",
        "    \"I won't say that the movie is astounding and I wouldn't claim that \\\n",
        "    the movie is too banal either.\",\n",
        "    \"I like to hate Michael Bay films, but I couldn't fault this one\",\n",
        "    \"It's one thing to watch an Uwe Boll film, but another thing entirely \\\n",
        "    to pay for it\",\n",
        "    \"The movie was too good\",\n",
        "    \"This movie was actually neither that funny, nor super witty.\",\n",
        "    \"This movie doesn't care about cleverness, wit or any other kind of \\\n",
        "    intelligent humor.\",\n",
        "    \"Those who find ugly meanings in beautiful things are corrupt without \\\n",
        "    being charming.\",\n",
        "    \"There are slow and repetitive parts, BUT it has just enough spice to \\\n",
        "    keep it interesting.\",\n",
        "    \"The script is not fantastic, but the acting is decent and the cinematography \\\n",
        "    is EXCELLENT!\",\n",
        "    \"Adam is one of the most compelling variations on this theme.\",\n",
        "    \"Adam is one of the least compelling variations on this theme.\",\n",
        "    \"Adam is at least compelling as a variation on the theme.\",\n",
        "    \"they fall in love with the product\",\n",
        "    \"but then it breaks\",\n",
        "    \"usually around the time the 90 day warranty expires\",\n",
        "    \"the twin towers collapsed today\",\n",
        "    \"However, Mr.Sood solemnly argues, his client carried out the kidnapping \\\n",
        "    under orders and in the ''least offensive way possible.''\"\n",
        " ]\n",
        "\n",
        "sentences.extend(tricky_sentences)"
      ],
      "metadata": {
        "id": "NoIGV5TRZ9e9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"It was one of the worst movies I've seen, despite good reviews. \\\n",
        " Unbelievably bad acting!! Poor direction. VERY poor production. \\\n",
        " The movie was bad. Very bad movie. VERY bad movie. VERY BAD movie. VERY BAD movie!\""
      ],
      "metadata": {
        "id": "hdUU-nBTaICb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "from nltk import tokenize\n",
        "lines_list = tokenize.sent_tokenize(paragraph)\n",
        "sentences.extend(lines_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuPYNvjwaK1a",
        "outputId": "7e07bdbd-a578-4075-e58d-c13d844cb0f7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "for sentence in sentences:\n",
        "     print(sentence)\n",
        "     ss = sid.polarity_scores(sentence)\n",
        "     for k in sorted(ss):\n",
        "         print('{0}: {1}, '.format(k, ss[k]), end='')\n",
        "     print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYE49KuFaTZ6",
        "outputId": "d31f8812-283f-4f54-f148-f1d3afbade00"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adamya is smart, handsome, and funny.\n",
            "compound: 0.8316, neg: 0.0, neu: 0.254, pos: 0.746, \n",
            "Adamya is smart, handsome, and funny!\n",
            "compound: 0.8439, neg: 0.0, neu: 0.248, pos: 0.752, \n",
            "Adamya is very smart, handsome, and funny.\n",
            "compound: 0.8545, neg: 0.0, neu: 0.299, pos: 0.701, \n",
            "Sood is VERY SMART, handsome, and FUNNY.\n",
            "compound: 0.9227, neg: 0.0, neu: 0.246, pos: 0.754, \n",
            "sood is VERY SMART, handsome, and FUNNY!!!\n",
            "compound: 0.9342, neg: 0.0, neu: 0.233, pos: 0.767, \n",
            "sood is VERY SMART, really handsome, and INCREDIBLY FUNNY!!!\n",
            "compound: 0.9469, neg: 0.0, neu: 0.294, pos: 0.706, \n",
            "The book was good.\n",
            "compound: 0.4404, neg: 0.0, neu: 0.508, pos: 0.492, \n",
            "The book was kind of good.\n",
            "compound: 0.3832, neg: 0.0, neu: 0.657, pos: 0.343, \n",
            "The plot was good, but the characters are uncompelling and the dialog is not great.\n",
            "compound: -0.7042, neg: 0.327, neu: 0.579, pos: 0.094, \n",
            "A really bad, horrible book.\n",
            "compound: -0.8211, neg: 0.791, neu: 0.209, pos: 0.0, \n",
            "At least it isn't a horrible book.\n",
            "compound: 0.431, neg: 0.0, neu: 0.637, pos: 0.363, \n",
            ":) and :D\n",
            "compound: 0.7925, neg: 0.0, neu: 0.124, pos: 0.876, \n",
            "\n",
            "compound: 0.0, neg: 0.0, neu: 0.0, pos: 0.0, \n",
            "Today sucks!\n",
            "compound: -0.4199, neg: 0.736, neu: 0.264, pos: 0.0, \n",
            "Today sucks!\n",
            "compound: -0.4199, neg: 0.736, neu: 0.264, pos: 0.0, \n",
            "Today SUcks!\n",
            "compound: -0.4199, neg: 0.736, neu: 0.264, pos: 0.0, \n",
            "Today kinda sucks! But I'll  make it , lol\n",
            "compound: 0.5249, neg: 0.138, neu: 0.517, pos: 0.344, \n",
            "Most automated sentiment analysis tools are shit.\n",
            "compound: -0.5574, neg: 0.375, neu: 0.625, pos: 0.0, \n",
            "VADER sentiment analysis is the shit.\n",
            "compound: 0.6124, neg: 0.0, neu: 0.556, pos: 0.444, \n",
            "Sentiment analysis has never been good.\n",
            "compound: -0.3412, neg: 0.325, neu: 0.675, pos: 0.0, \n",
            "Sentiment analysis with Adam has never been this good.\n",
            "compound: 0.5228, neg: 0.0, neu: 0.703, pos: 0.297, \n",
            "Adam has never been so entertaining.\n",
            "compound: 0.5777, neg: 0.0, neu: 0.572, pos: 0.428, \n",
            "I won't say that the movie is astounding and I wouldn't claim that     the movie is too banal either.\n",
            "compound: 0.4215, neg: 0.0, neu: 0.851, pos: 0.149, \n",
            "I like to hate Michael Bay films, but I couldn't fault this one\n",
            "compound: 0.3153, neg: 0.157, neu: 0.534, pos: 0.309, \n",
            "It's one thing to watch an Uwe Boll film, but another thing entirely     to pay for it\n",
            "compound: -0.2541, neg: 0.112, neu: 0.888, pos: 0.0, \n",
            "The movie was too good\n",
            "compound: 0.4404, neg: 0.0, neu: 0.58, pos: 0.42, \n",
            "This movie was actually neither that funny, nor super witty.\n",
            "compound: -0.6759, neg: 0.41, neu: 0.59, pos: 0.0, \n",
            "This movie doesn't care about cleverness, wit or any other kind of     intelligent humor.\n",
            "compound: -0.1338, neg: 0.265, neu: 0.497, pos: 0.239, \n",
            "Those who find ugly meanings in beautiful things are corrupt without     being charming.\n",
            "compound: -0.3553, neg: 0.314, neu: 0.493, pos: 0.192, \n",
            "There are slow and repetitive parts, BUT it has just enough spice to     keep it interesting.\n",
            "compound: 0.4678, neg: 0.079, neu: 0.735, pos: 0.186, \n",
            "The script is not fantastic, but the acting is decent and the cinematography     is EXCELLENT!\n",
            "compound: 0.7565, neg: 0.092, neu: 0.607, pos: 0.301, \n",
            "Adam is one of the most compelling variations on this theme.\n",
            "compound: 0.2944, neg: 0.0, neu: 0.82, pos: 0.18, \n",
            "Adam is one of the least compelling variations on this theme.\n",
            "compound: -0.1695, neg: 0.143, neu: 0.857, pos: 0.0, \n",
            "Adam is at least compelling as a variation on the theme.\n",
            "compound: 0.2263, neg: 0.0, neu: 0.826, pos: 0.174, \n",
            "they fall in love with the product\n",
            "compound: 0.6369, neg: 0.0, neu: 0.588, pos: 0.412, \n",
            "but then it breaks\n",
            "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
            "usually around the time the 90 day warranty expires\n",
            "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
            "the twin towers collapsed today\n",
            "compound: -0.2732, neg: 0.344, neu: 0.656, pos: 0.0, \n",
            "However, Mr.Sood solemnly argues, his client carried out the kidnapping     under orders and in the ''least offensive way possible.''\n",
            "compound: -0.5859, neg: 0.239, neu: 0.684, pos: 0.077, \n",
            "It was one of the worst movies I've seen, despite good reviews.\n",
            "compound: -0.7584, neg: 0.394, neu: 0.606, pos: 0.0, \n",
            "Unbelievably bad acting!!\n",
            "compound: -0.6572, neg: 0.686, neu: 0.314, pos: 0.0, \n",
            "Poor direction.\n",
            "compound: -0.4767, neg: 0.756, neu: 0.244, pos: 0.0, \n",
            "VERY poor production.\n",
            "compound: -0.6281, neg: 0.674, neu: 0.326, pos: 0.0, \n",
            "The movie was bad.\n",
            "compound: -0.5423, neg: 0.538, neu: 0.462, pos: 0.0, \n",
            "Very bad movie.\n",
            "compound: -0.5849, neg: 0.655, neu: 0.345, pos: 0.0, \n",
            "VERY bad movie.\n",
            "compound: -0.6732, neg: 0.694, neu: 0.306, pos: 0.0, \n",
            "VERY BAD movie.\n",
            "compound: -0.7398, neg: 0.724, neu: 0.276, pos: 0.0, \n",
            "VERY BAD movie!\n",
            "compound: -0.7616, neg: 0.735, neu: 0.265, pos: 0.0, \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}